# ğŸ§  Customer Churn & Lifetime Value Prediction

This is an end-to-end machine learning project to simulate and solve a real-world customer analytics problem. The project involves **predicting customer churn (classification)**, **forecasting customer lifetime value (regression)**, and **segmenting users (clustering)** using a synthetic customer dataset.

---

## ğŸš€ Project Objectives

- Predict whether a customer will **churn** or not
- Predict **LTV (Lifetime Value)** of a customer
- Cluster customers into natural **behavioral segments**
- Interpret model decisions for business transparency

---

## ğŸ“ Project Structure (Phases)

| Phase | Description |
|-------|-------------|
| **1. EDA** | Analyzed distributions, imbalances, outliers, temporal patterns |
| **2. Preprocessing** | Missing values, encoding, scaling, tenure extraction |
| **3. Feature Engineering** | RFM metrics, log transforms, transaction summaries |
| **4. Classification** | Models: Logistic Regression, Random Forest, XGBoost |
| **5. Regression** | LTV prediction with log transform + tree models |
| **6. Clustering** | PCA + KMeans to discover customer segments |
| **7. Tuning** | Hyperparameter tuning with `RandomizedSearchCV` |
| **8. Explainability** | Feature importances, SHAP (optional) |

---

## ğŸ“Š Datasets Used

- `customers.csv` â†’ demographics + signup info  
- `interactions.csv` â†’ complaints, satisfaction, tickets  
- `transactions.csv` â†’ purchases, timestamps, categories  
- `campaigns.csv` â†’ marketing click/purchase behavior

---

## ğŸ§  ML Models Used

### ğŸ”¹ Classification (Churn)
- Logistic Regression
- Random Forest Classifier âœ…
- XGBoost Classifier

**Best Results:**
- Precision: `~0.81`
- Recall: `~0.45`
- ROC-AUC: `~0.72`

---

### ğŸ”¸ Regression (LTV)
- Linear Regression
- Random Forest Regressor âœ…
- XGBoost Regressor

**Best Results (after log-transform):**
- MAE: `~1.32`
- RMSE: `~5.48`
- RÂ² Score: `~0.99998`

---

### ğŸ”º Clustering (Unsupervised)
- PCA for dimensionality reduction
- KMeans (k=3)
- Customer profiling using grouped means

---

## ğŸ” Key Insights

- **Satisfaction score & complaint count** were top churn drivers
- **Log-transforming LTV** greatly stabilized regression performance
- Customers clustered into:
  - Passive but loyal users
  - Highly engaged but risky churners
  - Average customers

---

## âš™ï¸ Tools & Libraries

- Python (pandas, numpy, matplotlib, seaborn)
- Scikit-learn
- XGBoost
- SHAP (optional)
- Jupyter Notebook

---

## ğŸ“ˆ Next Steps
- Add SHAP explainability for regression
- Deploy model with `Flask` or `Streamlit`
- Visual dashboard with Tableau or Plotly


